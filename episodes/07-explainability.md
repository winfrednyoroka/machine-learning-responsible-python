---
title: "Explainability"
teaching: 0
exercises: 0
questions:
- "Do we need explainable models?"
objectives:
- "Consider the importance of explainability in machine learning."
keypoints:
- "The importance of explainability is hotly debated."
---

## Explainability of machine learning models

Machine learning models - in particular neural networks - are often criticised for being "black boxes". If a model is making a prediction, many of us would like to know how the decision was reached. With this understanding, we gain trust. 

The requirement for explainability is even making its way into legal governance. The European Union General Data Protection (GDPR)) for example, states that "[the data subject should have] the right ... to obtain an explanation of the decision reached".

While at face value explainability seems like something that we would want in our models, this is a topic of much debate. https://arxiv.org/pdf/1702.08608.pdf

If our doctor or nurse recommends paracetamol (acetaminophen) for pain management, most of us would accept the suggestion without question. This is despite the action of paracetamol at a molecular level being unclear [https://pubmed.ncbi.nlm.nih.gov/15662292/]. 

Some would also argue that an explainable model creates trust where it is not well founded. A model may convince us that its reasoning is sound, even where it is not.

Examples, and discussion.

{% include links.md %}
