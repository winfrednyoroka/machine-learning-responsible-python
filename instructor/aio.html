<!DOCTYPE html>
<!-- START: inst/pkgdown/templates/layout.html --><!-- Generated by pkgdown: do not edit by hand --><html lang="en" data-bs-theme="auto">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<title>Responsible machine learning in Python: All in One View</title>
<meta name="viewport" content="width=device-width, initial-scale=1">
<script src="../assets/themetoggle.js"></script><link rel="stylesheet" type="text/css" href="../assets/styles.css">
<script src="../assets/scripts.js" type="text/javascript"></script><!-- mathjax --><script type="text/x-mathjax-config">
    MathJax.Hub.Config({
      config: ["MMLorHTML.js"],
      jax: ["input/TeX","input/MathML","output/HTML-CSS","output/NativeMML", "output/PreviewHTML"],
      extensions: ["tex2jax.js","mml2jax.js","MathMenu.js","MathZoom.js", "fast-preview.js", "AssistiveMML.js", "a11y/accessibility-menu.js"],
      TeX: {
        extensions: ["AMSmath.js","AMSsymbols.js","noErrors.js","noUndefined.js"]
      },
      tex2jax: {
        inlineMath: [['\\(', '\\)']],
        displayMath: [ ['$$','$$'], ['\\[', '\\]'] ],
        processEscapes: true
      }
    });
    </script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js" integrity="sha256-nvJJv9wWKEm88qvoQl9ekL2J+k/RWIsaSScxxlsrv8k=" crossorigin="anonymous"></script><!-- Responsive Favicon for The Carpentries --><link rel="apple-touch-icon" sizes="180x180" href="../favicons/incubator/apple-touch-icon.png">
<link rel="icon" type="image/png" sizes="32x32" href="../favicons/incubator/favicon-32x32.png">
<link rel="icon" type="image/png" sizes="16x16" href="../favicons/incubator/favicon-16x16.png">
<link rel="manifest" href="../favicons/incubator/site.webmanifest">
<link rel="mask-icon" href="../favicons/incubator/safari-pinned-tab.svg" color="#5bbad5">
<meta name="msapplication-TileColor" content="#da532c">
<meta name="theme-color" media="(prefers-color-scheme: light)" content="white">
<meta name="theme-color" media="(prefers-color-scheme: dark)" content="black">
</head>
<body>
    <header id="top" class="navbar navbar-expand-md top-nav incubator"><svg xmlns="http://www.w3.org/2000/svg" class="d-none"><symbol id="check2" viewbox="0 0 16 16"><path d="M13.854 3.646a.5.5 0 0 1 0 .708l-7 7a.5.5 0 0 1-.708 0l-3.5-3.5a.5.5 0 1 1 .708-.708L6.5 10.293l6.646-6.647a.5.5 0 0 1 .708 0z"></path></symbol><symbol id="circle-half" viewbox="0 0 16 16"><path d="M8 15A7 7 0 1 0 8 1v14zm0 1A8 8 0 1 1 8 0a8 8 0 0 1 0 16z"></path></symbol><symbol id="moon-stars-fill" viewbox="0 0 16 16"><path d="M6 .278a.768.768 0 0 1 .08.858 7.208 7.208 0 0 0-.878 3.46c0 4.021 3.278 7.277 7.318 7.277.527 0 1.04-.055 1.533-.16a.787.787 0 0 1 .81.316.733.733 0 0 1-.031.893A8.349 8.349 0 0 1 8.344 16C3.734 16 0 12.286 0 7.71 0 4.266 2.114 1.312 5.124.06A.752.752 0 0 1 6 .278z"></path><path d="M10.794 3.148a.217.217 0 0 1 .412 0l.387 1.162c.173.518.579.924 1.097 1.097l1.162.387a.217.217 0 0 1 0 .412l-1.162.387a1.734 1.734 0 0 0-1.097 1.097l-.387 1.162a.217.217 0 0 1-.412 0l-.387-1.162A1.734 1.734 0 0 0 9.31 6.593l-1.162-.387a.217.217 0 0 1 0-.412l1.162-.387a1.734 1.734 0 0 0 1.097-1.097l.387-1.162zM13.863.099a.145.145 0 0 1 .274 0l.258.774c.115.346.386.617.732.732l.774.258a.145.145 0 0 1 0 .274l-.774.258a1.156 1.156 0 0 0-.732.732l-.258.774a.145.145 0 0 1-.274 0l-.258-.774a1.156 1.156 0 0 0-.732-.732l-.774-.258a.145.145 0 0 1 0-.274l.774-.258c.346-.115.617-.386.732-.732L13.863.1z"></path></symbol><symbol id="sun-fill" viewbox="0 0 16 16"><path d="M8 12a4 4 0 1 0 0-8 4 4 0 0 0 0 8zM8 0a.5.5 0 0 1 .5.5v2a.5.5 0 0 1-1 0v-2A.5.5 0 0 1 8 0zm0 13a.5.5 0 0 1 .5.5v2a.5.5 0 0 1-1 0v-2A.5.5 0 0 1 8 13zm8-5a.5.5 0 0 1-.5.5h-2a.5.5 0 0 1 0-1h2a.5.5 0 0 1 .5.5zM3 8a.5.5 0 0 1-.5.5h-2a.5.5 0 0 1 0-1h2A.5.5 0 0 1 3 8zm10.657-5.657a.5.5 0 0 1 0 .707l-1.414 1.415a.5.5 0 1 1-.707-.708l1.414-1.414a.5.5 0 0 1 .707 0zm-9.193 9.193a.5.5 0 0 1 0 .707L3.05 13.657a.5.5 0 0 1-.707-.707l1.414-1.414a.5.5 0 0 1 .707 0zm9.193 2.121a.5.5 0 0 1-.707 0l-1.414-1.414a.5.5 0 0 1 .707-.707l1.414 1.414a.5.5 0 0 1 0 .707zM4.464 4.465a.5.5 0 0 1-.707 0L2.343 3.05a.5.5 0 1 1 .707-.707l1.414 1.414a.5.5 0 0 1 0 .708z"></path></symbol></svg><a class="visually-hidden-focusable skip-link" href="#main-content">Skip to main content</a>
  <div class="container-fluid top-nav-container">
    <div class="col-md-8">
      <div class="large-logo">
        <img id="incubator-logo" alt="Lesson Description" src="../assets/images/incubator-logo.svg"><span class="badge text-bg-info">
          <abbr title="This lesson is in the beta phase, which means that it is ready for teaching by instructors outside of the original author team.">
            <a href="https://cdh.carpentries.org/the-lesson-life-cycle.html#polishing-beta-stage" class="external-link alert-link">
              <i aria-hidden="true" class="icon" data-feather="alert-circle" style="border-radius: 5px"></i>
              Beta
            </a>
            <span class="visually-hidden">This lesson is in the beta phase, which means that it is ready for teaching by instructors outside of the original author team.</span>
          </abbr>
        </span>

      </div>
    </div>
    <div class="selector-container">
      <div id="theme-selector">
        <li class="nav-item dropdown" id="theme-button-list">
          <button class="btn btn-link nav-link px-0 px-lg-2 dropdown-toggle d-flex align-items-center" id="bd-theme" type="button" aria-expanded="false" data-bs-toggle="dropdown" data-bs-display="static" aria-label="Toggle theme (auto)">
            <svg class="bi my-1 theme-icon-active"><use href="#circle-half"></use></svg><i data-feather="chevron-down"></i>
          </button>
          <ul class="dropdown-menu dropdown-menu-end" aria-labelledby="bd-theme-text">
<li>
              <button type="button" class="btn dropdown-item d-flex align-items-center" data-bs-theme-value="light" aria-pressed="false">
                <svg class="bi me-2 theme-icon"><use href="#sun-fill"></use></svg>
                Light
                <svg class="bi ms-auto d-none"><use href="#check2"></use></svg></button>
            </li>
            <li>
              <button type="button" class="btn dropdown-item d-flex align-items-center" data-bs-theme-value="dark" aria-pressed="false">
                <svg class="bi me-2 theme-icon"><use href="#moon-stars-fill"></use></svg>
                Dark
                <svg class="bi ms-auto d-none"><use href="#check2"></use></svg></button>
            </li>
            <li>
              <button type="button" class="btn dropdown-item d-flex align-items-center active" data-bs-theme-value="auto" aria-pressed="true">
                <svg class="bi me-2 theme-icon"><use href="#circle-half"></use></svg>
                Auto
                <svg class="bi ms-auto d-none"><use href="#check2"></use></svg></button>
            </li>
          </ul>
</li>
      </div>

      <div class="dropdown" id="instructor-dropdown">
        <button class="btn btn-secondary dropdown-toggle bordered-button" type="button" id="dropdownMenu1" data-bs-toggle="dropdown" aria-expanded="false">
          <i aria-hidden="true" class="icon" data-feather="eye"></i> Instructor View <i data-feather="chevron-down"></i>
        </button>
        <ul class="dropdown-menu" aria-labelledby="dropdownMenu1">
<li><button class="dropdown-item" type="button" onclick="window.location.href='../aio.html';">Learner View</button></li>
        </ul>
</div>
    </div>
  </div>
  <hr></header><nav class="navbar navbar-expand-xl bottom-nav incubator" aria-label="Main Navigation"><div class="container-fluid nav-container">
    <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarSupportedContent" aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle Navigation">
      <span class="navbar-toggler-icon"></span>
      <span class="menu-title">Menu</span>
    </button>
    <div class="nav-logo">
      <img class="small-logo" alt="Lesson Description" src="../assets/images/incubator-logo-sm.svg">
</div>
    <div class="lesson-title-md">
      Responsible machine learning in Python
    </div>
    <div class="search-icon-sm">
      <!-- TODO: do not show until we have search
        <i role="img" aria-label="Search the All In One page" data-feather="search"></i>
      -->
    </div>
    <div class="desktop-nav">
      <ul class="navbar-nav me-auto mb-2 mb-lg-0">
<li class="nav-item">
          <span class="lesson-title">
            Responsible machine learning in Python
          </span>
        </li>
        <li class="nav-item">
          <a class="nav-link" href="../instructor/key-points.html">Key Points</a>
        </li>
        <li class="nav-item">
          <a class="nav-link" href="../instructor/instructor-notes.html">Instructor Notes</a>
        </li>
        <li class="nav-item">
          <a class="nav-link" href="../instructor/images.html">Extract All Images</a>
        </li>
        <li class="nav-item dropdown">
          <button class="nav-link dropdown-toggle" id="navbarDropdown" data-bs-toggle="dropdown" aria-expanded="false">
            More <i data-feather="chevron-down"></i>
          </button>
          <ul class="dropdown-menu" aria-labelledby="navbarDropdown">
<hr>
<li><a class="dropdown-item" href="discuss.html">Discussion</a></li>
<li><a class="dropdown-item" href="reference.html">Glossary</a></li>
          </ul>
</li>
      </ul>
</div>
    <!--
    <form class="d-flex col-md-2 search-form">
      <fieldset disabled>
      <input class="form-control me-2 searchbox" type="search" placeholder="" aria-label="">
        <button class="btn btn-outline-success tablet-search-button"  type="submit">
          <i class="search-icon" data-feather="search" role="img" aria-label="Search the All In One page"></i>
        </button>
      </fieldset>
    </form>
    -->
    <a id="search-button" class="btn btn-primary" href="../instructor/aio.html" role="button" aria-label="Search the All In One page">Search the All In One page</a>
  </div>
<!--/div.container-fluid -->
</nav><div class="col-md-12 mobile-title">
  Responsible machine learning in Python
</div>

<aside class="col-md-12 lesson-progress"><div style="width: %" class="percentage">
    %
  </div>
  <div class="progress incubator">
    <div class="progress-bar incubator" role="progressbar" style="width: %" aria-valuenow="" aria-label="Lesson Progress" aria-valuemin="0" aria-valuemax="100">
    </div>
  </div>
</aside><div class="container">
      <div class="row">
        <!-- START: inst/pkgdown/templates/navbar.html -->
<div id="sidebar-col" class="col-lg-4">
  <div id="sidebar" class="sidebar">
      <nav aria-labelledby="flush-headingEleven"><button role="button" aria-label="close menu" alt="close menu" aria-expanded="true" aria-controls="sidebar" class="collapse-toggle" data-collapse="Collapse " data-episodes="Episodes ">
          <i class="search-icon" data-feather="x" role="img"></i>
        </button>
        <div class="sidebar-inner">
          <div class="row mobile-row" id="theme-row-mobile">
            <div class="col" id="theme-selector">
              <li class="nav-item dropdown" id="theme-button-list">
                <button class="btn btn-link nav-link px-0 px-lg-2 dropdown-toggle d-flex align-items-center" id="bd-theme" type="button" aria-expanded="false" data-bs-toggle="dropdown" data-bs-display="static" aria-label="Toggle theme (auto)">
                  <svg class="bi my-1 theme-icon-active"><use href="#circle-half"></use></svg><span class="d-lg-none ms-1" id="bd-theme-text">Toggle Theme</span>
                </button>
                <ul class="dropdown-menu dropdown-menu-right" aria-labelledby="bd-theme-text">
<li>
                    <button type="button" class="btn dropdown-item d-flex align-items-center" data-bs-theme-value="light" aria-pressed="false">
                      <svg class="bi me-2 theme-icon"><use href="#sun-fill"></use></svg>
                      Light
                      <svg class="bi ms-auto d-none"><use href="#check2"></use></svg></button>
                  </li>
                  <li>
                    <button type="button" class="btn dropdown-item d-flex align-items-center" data-bs-theme-value="dark" aria-pressed="false">
                      <svg class="bi me-2 theme-icon"><use href="#moon-stars-fill"></use></svg>
                      Dark
                      <svg class="bi ms-auto d-none"><use href="#check2"></use></svg></button>
                  </li>
                  <li>
                    <button type="button" class="btn dropdown-item d-flex align-items-center active" data-bs-theme-value="auto" aria-pressed="true">
                      <svg class="bi me-2 theme-icon"><use href="#circle-half"></use></svg>
                      Auto
                      <svg class="bi ms-auto d-none"><use href="#check2"></use></svg></button>
                  </li>
                </ul>
</li>
            </div>
          </div>
          <div class="row mobile-row">
            <div class="col">
              <div class="sidenav-view-selector">
                <div class="accordion accordion-flush" id="accordionFlush9">
                  <div class="accordion-item">
                    <h2 class="accordion-header" id="flush-headingNine">
                      <button class="accordion-button collapsed" id="instructor" type="button" data-bs-toggle="collapse" data-bs-target="#flush-collapseNine" aria-expanded="false" aria-controls="flush-collapseNine">
                        <i id="eye" aria-hidden="true" class="icon" data-feather="eye"></i> Instructor View
                      </button>
                    </h2>
                    <div id="flush-collapseNine" class="accordion-collapse collapse" aria-labelledby="flush-headingNine" data-bs-parent="#accordionFlush2">
                      <div class="accordion-body">
                        <a href="../aio.html">Learner View</a>
                      </div>
                    </div>
                  </div>
<!--/div.accordion-item-->
                </div>
<!--/div.accordion-flush-->
              </div>
<!--div.sidenav-view-selector -->
            </div>
<!--/div.col -->

            <hr>
</div>
<!--/div.mobile-row -->

          <div class="accordion accordion-flush" id="accordionFlush11">
            <div class="accordion-item">

              <button id="chapters" class="accordion-button show" type="button" data-bs-toggle="collapse" data-bs-target="#flush-collapseEleven" aria-expanded="false" aria-controls="flush-collapseEleven">
                <h2 class="accordion-header chapters" id="flush-headingEleven">
                  EPISODES
                </h2>
              </button>
              <div id="flush-collapseEleven" class="accordion-collapse show collapse" aria-labelledby="flush-headingEleven" data-bs-parent="#accordionFlush11">

                <div class="accordion-body">
                  <div class="accordion accordion-flush" id="accordionFlush1">
  <div class="accordion-item">
    <div class="accordion-header" id="flush-heading1">
        <a href="index.html">Summary and Schedule</a>
    </div>
<!--/div.accordion-header-->

  </div>
<!--/div.accordion-item-->
</div>
<!--/div.accordion-flush-->

<div class="accordion accordion-flush" id="accordionFlush2">
  <div class="accordion-item">
    <div class="accordion-header" id="flush-heading2">
        <a href="01-introduction.html">1. Introduction</a>
    </div>
<!--/div.accordion-header-->

  </div>
<!--/div.accordion-item-->
</div>
<!--/div.accordion-flush-->

<div class="accordion accordion-flush" id="accordionFlush3">
  <div class="accordion-item">
    <div class="accordion-header" id="flush-heading3">
        <a href="02-tasks.html">2. Tasks</a>
    </div>
<!--/div.accordion-header-->

  </div>
<!--/div.accordion-item-->
</div>
<!--/div.accordion-flush-->

<div class="accordion accordion-flush" id="accordionFlush4">
  <div class="accordion-item">
    <div class="accordion-header" id="flush-heading4">
        <a href="03-data.html">3. Data</a>
    </div>
<!--/div.accordion-header-->

  </div>
<!--/div.accordion-item-->
</div>
<!--/div.accordion-flush-->

<div class="accordion accordion-flush" id="accordionFlush5">
  <div class="accordion-item">
    <div class="accordion-header" id="flush-heading5">
        <a href="04-bias.html">4. Fairness</a>
    </div>
<!--/div.accordion-header-->

  </div>
<!--/div.accordion-item-->
</div>
<!--/div.accordion-flush-->

<div class="accordion accordion-flush" id="accordionFlush6">
  <div class="accordion-item">
    <div class="accordion-header" id="flush-heading6">
        <a href="05-shift.html">5. Dataset shift</a>
    </div>
<!--/div.accordion-header-->

  </div>
<!--/div.accordion-item-->
</div>
<!--/div.accordion-flush-->

<div class="accordion accordion-flush" id="accordionFlush7">
  <div class="accordion-item">
    <div class="accordion-header" id="flush-heading7">
        <a href="06-explainability.html">6. Explainability</a>
    </div>
<!--/div.accordion-header-->

  </div>
<!--/div.accordion-item-->
</div>
<!--/div.accordion-flush-->

<div class="accordion accordion-flush" id="accordionFlush8">
  <div class="accordion-item">
    <div class="accordion-header" id="flush-heading8">
        <a href="07-attacks.html">7. Attacks</a>
    </div>
<!--/div.accordion-header-->

  </div>
<!--/div.accordion-item-->
</div>
<!--/div.accordion-flush-->

                </div>
              </div>
            </div>

            <hr class="half-width">
<div class="accordion accordion-flush lesson-resources" id="accordionFlush12">
              <div class="accordion-item">
                <h2 class="accordion-header" id="flush-headingTwelve">
                  <button class="accordion-button collapsed" id="lesson-resources" type="button" data-bs-toggle="collapse" data-bs-target="#flush-collapseTwelve" aria-expanded="false" aria-controls="flush-collapseTwelve">
                    RESOURCES
                  </button>
                </h2>
                <div id="flush-collapseTwelve" class="accordion-collapse collapse" aria-labelledby="flush-headingTwelve" data-bs-parent="#accordionFlush12">
                  <div class="accordion-body">
                    <ul>
<li>
                        <a href="../instructor/key-points.html">Key Points</a>
                      </li>
                      <li>
                        <a href="../instructor/instructor-notes.html">Instructor Notes</a>
                      </li>
                      <li>
                        <a href="../instructor/images.html">Extract All Images</a>
                      </li>
                      <hr>
<li><a class="dropdown-item" href="discuss.html">Discussion</a></li>
<li><a class="dropdown-item" href="reference.html">Glossary</a></li>
                    </ul>
</div>
                </div>
              </div>
            </div>
            <hr class="half-width lesson-resources">
<a href="../instructor/aio.html">See all in one page</a>


            <hr class="d-none d-sm-block d-md-none">
<div class="d-grid gap-1">

            </div>
          </div>
<!-- /div.accordion -->
        </div>
<!-- /div.sidebar-inner -->
      </nav>
</div>
<!-- /div.sidebar -->
  </div>
<!-- /div.sidebar-col -->
<!-- END:   inst/pkgdown/templates/navbar.html-->

        <!-- START: inst/pkgdown/templates/content-extra.html -->
  <div class="col-xl-8 col-lg-12 primary-content">
    <main id="main-content" class="main-content"><div class="container lesson-content">
        
        
<section id="aio-01-introduction"><p>Content from <a href="01-introduction.html">Introduction</a></p>
<hr>
<p>Last updated on 2024-11-14 |

        <a href="https://github.com/carpentries-incubator/machine-learning-responsible-python/edit/main/episodes/01-introduction.md" class="external-link">Edit this page <i aria-hidden="true" data-feather="edit"></i></a></p>
<p>Estimated time: <i aria-hidden="true" data-feather="clock"></i> 30 minutes</p>
<div class="text-end">
          <button role="button" aria-pressed="false" tabindex="0" id="expand-code" class="pull-right" data-expand="Expand All Solutions " data-collapse="Collapse All Solutions "> Expand All Solutions <i aria-hidden="true" data-feather="plus"></i></button>
        </div>
<div class="overview card">
<h2 class="card-header">Overview</h2>
<div class="row g-0">
<div class="col-md-4">
<div class="card-body">
<div class="inner">
<h3 class="card-title">Questions</h3>
<ul>
<li>What do we mean by responsible machine learning?</li>
<li>What types of harm may result from development and deployment of
machine learning models?</li>
<li>What steps are being taken to mitigate the risks of harm?</li>
</ul>
</div>
</div>
</div>
<div class="col-md-8">
<div class="card-body">
<div class="inner bordered">
<h3 class="card-title">Objectives</h3>
<ul>
<li>Understand what is meant by responsible machine learning.</li>
<li>Recognise the types of harm that may be a consequence of machine
learning</li>
<li>Recognise the current state of oversight and regulation of machine
learning</li>
</ul>
</div>
</div>
</div>
</div>
</div>
<section><h2 class="section-heading" id="responsible-machine-learning">Responsible machine learning<a class="anchor" aria-label="anchor" href="#responsible-machine-learning"></a>
</h2>
<hr class="half-width">
<!--

TODO: reduce length of abstracts? Or avoid reading them and ask to read them.


TODO:
# Guidelines and quality criteria for artificial intelligence-based prediction models in healthcare
https://www.nature.com/articles/s41746-021-00549-7

--><p>Like many technologies, machine learning has the potential to cause
harm if applied inappropriately. With machine learning the issues can be
subtle: a seemingly good model may in fact be anything but. As an
emerging technology, machine learning is largely self-regulated so
awareness of potential pitfalls is especially important.</p>
<p>In this lesson we look broadly at a number of topics that are
important for applying machine learning in a responsible manner. We do
not attempt to define “responsible machine learning”, but we cover
topics that a person who practices machine learning should be aware of.
Topics range from choosing appropriate tasks, to awareness of sources of
bias, to the susceptibility of models to manipulation.</p>
<p>Given that “Artificial Intelligence” (or “A.I.”) has largely become a
synonym for machine learning, especially in popular culture, we will use
these terms interchangeably.</p>
<!-- Are concerns about the risks of machine learning warranted? We believe so. Machine learning models have quickly become part of everyday life. Models have caused physical harm (think autonomous driving and automated medical diagnosis)

https://www.antidiskriminierungsstelle.de/EN/homepage/_documents/download_diskr_risiken_verwendung_von_algorithmen.pdf?__blob=publicationFile&v=1
-->
</section><section><h2 class="section-heading" id="potential-harm">Potential harm<a class="anchor" aria-label="anchor" href="#potential-harm"></a>
</h2>
<hr class="half-width">
<p>What are some examples of machine learning systems that are already
in active public use? What kinds of harm could result from the
application of machine learning systems? Should we be concerned or are
these risks overhyped?</p>
<p>In their <a href="https://www.turing.ac.uk/sites/default/files/2019-08/understanding_artificial_intelligence_ethics_and_safety.pdf" class="external-link">guide
to Understanding artificial intelligence ethics and safety</a> The
Turing Institute highlight examples of the kind of harm that may result
from application of machine learning system.</p>
<div id="exercise" class="callout challenge">
<div class="callout-square">
<i class="callout-icon" data-feather="zap"></i>
</div>
<div id="exercise" class="callout-inner">
<h3 class="callout-title">Exercise</h3>
<div class="callout-content">
<p>Take a look at the table on pages 5-6 of the Turing Report. What
categories of harm are highlighted?</p>
</div>
</div>
</div>
<div id="accordionSolution1" class="accordion challenge-accordion accordion-flush">
<div class="accordion-item">
<button class="accordion-button solution-button collapsed" type="button" data-bs-toggle="collapse" data-bs-target="#collapseSolution1" aria-expanded="false" aria-controls="collapseSolution1">
  <h4 class="accordion-header" id="headingSolution1"> Show me the solution </h4>
</button>
<div id="collapseSolution1" class="accordion-collapse collapse" data-bs-parent="#accordionSolution1" aria-labelledby="headingSolution1">
<div class="accordion-body">
<ul>
<li>Bias and Discrimination</li>
<li>Denial of Individual Autonomy, Recourse, and Rights</li>
<li>Non-transparent, Unexplainable, or Unjustifiable Outcomes</li>
<li>Invasions of Privacy</li>
<li>Isolation and Disintegration of Social Connection</li>
<li>Unreliable, Unsafe, or Poor-Quality Outcomes</li>
</ul>
</div>
</div>
</div>
</div>
</section><section><h2 class="section-heading" id="need-for-oversight">Need for oversight<a class="anchor" aria-label="anchor" href="#need-for-oversight"></a>
</h2>
<hr class="half-width">
<p>In recent years there have been important changes that have sought to
introduce scrutiny and safeguards to the development and application of
machine learning. A <a href="https://web.archive.org/web/20200101022756/https://acm-fca.org/2018/03/29/negativeimpacts/" class="external-link">2018
statement</a> by scientists at the Association for Computing Machinery
(ACM), for example, highlighted growing concerns around lack of
oversight:</p>
<blockquote>
<p>“There clearly is a massive gap between the real-world impacts of
computing research and the positivity with which we in the computing
community tend to view our work. We believe that this gap represents a
serious and embarrassing intellectual lapse. The scale of this lapse is
truly tremendous: it is analogous to the medical community only writing
about the benefits of a given treatment and completely ignoring the side
effects, no matter how serious they are.”</p>
</blockquote>
<div id="exercise-1" class="callout challenge">
<div class="callout-square">
<i class="callout-icon" data-feather="zap"></i>
</div>
<div id="exercise-1" class="callout-inner">
<h3 class="callout-title">Exercise</h3>
<div class="callout-content">
<p>Take a few moments to <a href="https://web.archive.org/web/20200101022756/https://acm-fca.org/2018/03/29/negativeimpacts/" class="external-link">read
the ACM statement</a>.</p>
<ol style="list-style-type: upper-alpha">
<li>What are some of the negative impacts of research reported in the
article?<br>
</li>
<li>What “small change” do the authors suggest could have a big
impact?</li>
</ol>
</div>
</div>
</div>
<div id="accordionSolution2" class="accordion challenge-accordion accordion-flush">
<div class="accordion-item">
<button class="accordion-button solution-button collapsed" type="button" data-bs-toggle="collapse" data-bs-target="#collapseSolution2" aria-expanded="false" aria-controls="collapseSolution2">
  <h4 class="accordion-header" id="headingSolution2"> Show me the solution </h4>
</button>
<div id="collapseSolution2" class="accordion-collapse collapse" data-bs-parent="#accordionSolution2" aria-labelledby="headingSolution2">
<div class="accordion-body">
<ol style="list-style-type: upper-alpha">
<li><p>Points include: Disruption of careers; Generated audio and video
might threaten democracy; Decline in privacy rights; Spread of false
information, conspiracy theories, and propaganda.</p></li>
<li><p>“Peer reviewers should require that papers and proposals
rigorously consider all reasonable broader impacts, both positive and
negative.” Where projects were likely to have a net negative impact, the
statement suggests that authors “be encouraged to discuss complementary
technologies, policy, or other interventions that could mitigate the
negative broader impacts”.</p></li>
</ol>
</div>
</div>
</div>
</div>
</section><section><h2 class="section-heading" id="impact-statements">Impact statements<a class="anchor" aria-label="anchor" href="#impact-statements"></a>
</h2>
<hr class="half-width">
<p>In 2020, for the first time the <a href="https://neurips.cc/Conferences/2020/CallForPapers" class="external-link">call for
papers</a> for the Conference and Workshop on Neural Information
Processing Systems (NeurIPS), one of the largest machine learning
conferences, introduced a requirement for authors to reflect on
potential positive and negative consequences of their work with a
statement on “broader impact”:</p>
<blockquote>
<p>In order to provide a balanced perspective, authors are required to
include a statement of the potential broader impact of their work,
including its ethical aspects and future societal consequences. Authors
should take care to discuss both positive and negative outcomes.</p>
</blockquote>
<p>While questions remain about the effectiveness of this policy change,
it demonstrates growing recognition of the importance of responsible
machine learning and it is a step towards the research oversight that
many believe is needed. An <a href="https://arxiv.org/pdf/2105.04760.pdf" class="external-link">analysis of the
statements</a> that were submitted to the 2020 conference found that the
broader impact statements raised concerns in several areas:</p>
<div id="exercise-2" class="callout challenge">
<div class="callout-square">
<i class="callout-icon" data-feather="zap"></i>
</div>
<div id="exercise-2" class="callout-inner">
<h3 class="callout-title">Exercise</h3>
<div class="callout-content">
<p>Take a look at Section 5.1.2 of the <a href="https://arxiv.org/pdf/2105.04760.pdf" class="external-link">analysis</a> on Types of
Impacts (beginning page 5).</p>
<p>What are some of the concerns that were raised in the impact
statements?</p>
</div>
</div>
</div>
<div id="accordionSolution3" class="accordion challenge-accordion accordion-flush">
<div class="accordion-item">
<button class="accordion-button solution-button collapsed" type="button" data-bs-toggle="collapse" data-bs-target="#collapseSolution3" aria-expanded="false" aria-controls="collapseSolution3">
  <h4 class="accordion-header" id="headingSolution3"> Show me the solution </h4>
</button>
<div id="collapseSolution3" class="accordion-collapse collapse" data-bs-parent="#accordionSolution3" aria-labelledby="headingSolution3">
<div class="accordion-body">
<p>Concerns raised in the impact statements included:</p>
<ul>
<li>Privacy: impact around personal data and surveillance.</li>
<li>Labor: impact on employment and productivity.</li>
<li>Environment: impact on the environment, including the carbon
footprint of training models.</li>
<li>Media: impact in the media, particularly around fake news and
misinformation.</li>
<li>Bias: impact in terms of fairness and discrimination.</li>
<li>Reliability: impact of models that failed to meet expectations.</li>
<li>Interpretability: impact of the opaqueness of models and the “black
box problem”.</li>
</ul>
</div>
</div>
</div>
</div>
</section><section><h2 class="section-heading" id="regulation">Regulation<a class="anchor" aria-label="anchor" href="#regulation"></a>
</h2>
<hr class="half-width">
<p>The European Commission meanwhile is <a href="https://digital-strategy.ec.europa.eu/en/policies/regulatory-framework-ai" class="external-link">developing
a regulatory framework</a> with the goal of mitigating the risks of
“artificial intelligence” across Europe and beyond. The <a href="https://eur-lex.europa.eu/legal-content/EN/TXT/HTML/?uri=CELEX:52021PC0206&amp;from=EN" class="external-link">proposed
regulation</a> follows a risk-based approach, differentiating between
uses of artificial intelligence that create (i) an unacceptable risk,
(ii) a high risk, and (iii) low or minimal risk.</p>
<p>Systems that are deemed to have “unacceptable risk” - such as “social
scoring by governments” and “toys using voice assistance that encourages
dangerous behaviour” - would be banned. “High risk” systems - such as
artificial intelligence assisted surgery - would be tightly regulated.
The high-risk systems would, for example, be required to be trained on
“high quality” datasets; to keep a log of their activity; and to be
subject to human oversight.</p>
<div id="keypoints1" class="callout keypoints">
<div class="callout-square">
<i class="callout-icon" data-feather="key"></i>
</div>
<div class="callout-inner">
<h3 class="callout-title">Key Points</h3>
<div class="callout-content">
<ul>
<li>There is potential for machine learning models to cause harm.</li>
<li>Researchers are increasingly required to reflect on the impact of
their work.</li>
<li>Regulation and oversight are in their infancy.</li>
</ul>
</div>
</div>
</div>
</section></section><section id="aio-02-tasks"><p>Content from <a href="02-tasks.html">Tasks</a></p>
<hr>
<p>Last updated on 2024-11-14 |

        <a href="https://github.com/carpentries-incubator/machine-learning-responsible-python/edit/main/episodes/02-tasks.md" class="external-link">Edit this page <i aria-hidden="true" data-feather="edit"></i></a></p>
<p>Estimated time: <i aria-hidden="true" data-feather="clock"></i> 30 minutes</p>
<div class="text-end">
          <button role="button" aria-pressed="false" tabindex="0" id="expand-code" class="pull-right" data-expand="Expand All Solutions " data-collapse="Collapse All Solutions "> Expand All Solutions <i aria-hidden="true" data-feather="plus"></i></button>
        </div>
<div class="overview card">
<h2 class="card-header">Overview</h2>
<div class="row g-0">
<div class="col-md-4">
<div class="card-body">
<div class="inner">
<h3 class="card-title">Questions</h3>
<ul>
<li>Which tasks are appropriate for machine learning?</li>
<li>What are the principles of ethical machine learning?</li>
</ul>
</div>
</div>
</div>
<div class="col-md-8">
<div class="card-body">
<div class="inner bordered">
<h3 class="card-title">Objectives</h3>
<ul>
<li>Become familiar with principles for ethical research.</li>
<li>Consider whether tasks are appropriate for machine learning.</li>
</ul>
</div>
</div>
</div>
</div>
</div>
<section><h2 class="section-heading" id="tackling-the-right-tasks">Tackling the right tasks<a class="anchor" aria-label="anchor" href="#tackling-the-right-tasks"></a>
</h2>
<hr class="half-width">
<p>Machine learning is a rapidly advancing, powerful technology that is
helping to drive innovation. Before embarking on a machine learning
project, we need to consider the task carefully. Many machine learning
efforts are not solving problems that need to be solved. Worse, many
applications of machine learning are not for the public good.</p>
<p>The <a href="https://www.nih.gov/health-information/nih-clinical-research-trials-you/guiding-principles-ethical-research" class="external-link">NIH
Guiding Principles for Ethical Research</a> provide a useful set of
considerations for any project.</p>
<div id="exercise" class="callout challenge">
<div class="callout-square">
<i class="callout-icon" data-feather="zap"></i>
</div>
<div id="exercise" class="callout-inner">
<h3 class="callout-title">Exercise</h3>
<div class="callout-content">
<p>Take a look at the NIH Guiding Principles for Ethical Research.</p>
<p>What are the main principles?</p>
</div>
</div>
</div>
<div id="accordionSolution1" class="accordion challenge-accordion accordion-flush">
<div class="accordion-item">
<button class="accordion-button solution-button collapsed" type="button" data-bs-toggle="collapse" data-bs-target="#collapseSolution1" aria-expanded="false" aria-controls="collapseSolution1">
  <h4 class="accordion-header" id="headingSolution1"> Show me the solution </h4>
</button>
<div id="collapseSolution1" class="accordion-collapse collapse" data-bs-parent="#accordionSolution1" aria-labelledby="headingSolution1">
<div class="accordion-body">
<p>A summary of the principles is listed below:</p>
<ul>
<li>Social and clinical value: Does the social or clinical value of
developing and implementing the model outweigh the risk and burden of
the people involved?</li>
<li>Scientific validity: Once created, will the model provide valid,
meaningful outputs?</li>
<li>Fair subject selection: Are the people who contribute and benefit
from the model selected fairly, and not through vulnerability,
privilege, or other unrelated factors?</li>
<li>Favorable risk-benefit ratio: Do the potential benefits of of
developing and implementing the model outweigh the risks?</li>
<li>Independent review: Has the project been reviewed by someone
independent of the project, and has an Institutional Review Board (IRB)
been approached where appropriate?</li>
<li>Informed consent: Are participants whose data contributes to
development and implementation of the model, as well as downstream
recipients of the model, kept informed?</li>
<li>Respect for potential and enrolled subjects: Is the privacy of
participants respected and are steps taken to continuously monitor the
effect of the model on downstream participants?</li>
</ul>
</div>
</div>
</div>
</div>
<p>What kind of tasks should we be trying to tackle? How much should we
worry about technology being misused several years down the line? The
answers are not always clear. Here we explore some cases that have
raised concerns relating to discrimination, misinformation, and
privacy.</p>
</section><section><h2 class="section-heading" id="identifying-genetic-disorders">Identifying genetic disorders<a class="anchor" aria-label="anchor" href="#identifying-genetic-disorders"></a>
</h2>
<hr class="half-width">
<p>In 2019, Nature Medicine <a href="https://www.nature.com/articles/s41591-018-0279-0.epdf" class="external-link">published
a paper</a> that described work to develop a model that could identify
genetic disorders from a photograph of a patient’s face. The abstract of
the paper is copied below:</p>
<blockquote>
<p>Syndromic genetic conditions, in aggregate, affect 8% of the
population. Many syndromes have recognizable facial features that are
highly informative to clinical geneticists. Recent studies show that
facial analysis technologies measured up to the capabilities of expert
clinicians in syndrome identification. However, these technologies
identified only a few disease phenotypes, limiting their role in
clinical settings, where hundreds of diagnoses must be considered. Here
we present a facial image analysis framework, DeepGestalt, using
computer vision and deep-learning algorithms, that quantifies
similarities to hundreds of syndromes.</p>
<p>DeepGestalt outperformed clinicians in three initial experiments, two
with the goal of distinguishing subjects with a target syndrome from
other syndromes, and one of separating different genetic sub-types in
Noonan syndrome. On the final experiment reflecting a real clinical
setting problem, DeepGestalt achieved 91% top-10 accuracy in identifying
the correct syndrome on 502 different images. The model was trained on a
dataset of over 17,000 images representing more than 200 syndromes,
curated through a community-driven phenotyping platform. DeepGestalt
potentially adds considerable value to phenotypic evaluations in
clinical genetics, genetic testing, research and precision medicine.</p>
</blockquote>
<ul>
<li>What is the proposed value of the algorithm?</li>
<li>What are the potential risks?</li>
<li>Are you supportive of this kind of research?</li>
</ul>
<p>This technology underpins a phone app called Face2Gene, which is able
to report on genetic conditions at the snap of a person’s face. Media
reports on the technology generally favourably, for example reporting on
the <a href="https://www.genengnews.com/insights/a-i-gets-in-the-face-of-rare-genetic-diseases/" class="external-link">excitement
of clinicians at this technology</a>:</p>
<blockquote>
<p>In a room full of clinical geneticists, he projected many faces of
people who had been diagnosed with varying dysmorphic diseases and asked
the physicians to assign a genetic disorder to each face. Suffice it to
say, the physicians performed poorly—far worse than the computer…One of
the most exciting aspects of the program … is its ease. After asking
just one question to a patient, “is it ok if I take a picture?” and
snapping a quick photo, the program offers results back within
seconds.</p>
</blockquote>
<!-- >
https://www.nature.com/articles/d41586-019-00027-x

- "Face2Gene's recognition rate for Down syndrome was 80% among white Belgian children, it was just 37% for black Congolese children" affect your view?
-->
</section><section><h2 class="section-heading" id="reading-a-persons-face">“Reading” a person’s face<a class="anchor" aria-label="anchor" href="#reading-a-persons-face"></a>
</h2>
<hr class="half-width">
<p>There is a long history of physiognomy, the “science” of trying to
read someone’s character from their face. With the advent of machine
learning, this discredited area of research has made a comeback. There
have been numerous studies attempting to guess characteristics such as
trustworthness, criminality, and political and sexual orientation.</p>
<p>In 2018, for example, researchers <a href="https://www.gsb.stanford.edu/faculty-research/publications/deep-neural-networks-are-more-accurate-humans-detecting-sexual" class="external-link">suggested
that</a> neural networks could be used to detect sexual orientation from
facial images. The abstract is copied below:</p>
<blockquote>
<p>We show that faces contain much more information about sexual
orientation than can be perceived and interpreted by the human brain. We
used deep neural networks to extract features from 35,326 facial images.
These features were entered into a logistic regression aimed at
classifying sexual orientation. Given a single facial image, a
classifier could correctly distinguish between gay and heterosexual men
in 81% of cases, and in 74% of cases for women. Human judges achieved
much lower accuracy: 61% for men and 54% for women. The accuracy of the
algorithm increased to 91% and 83%, respectively, given five facial
images per person.</p>
<p>Facial features employed by the classifier included both fixed (e.g.,
nose shape) and transient facial features (e.g., grooming style).
Consistent with the prenatal hormone theory of sexual orientation, gay
men and women tended to have gender-atypical facial morphology,
expression, and grooming styles. Prediction models aimed at gender alone
allowed for detecting gay males with 57% accuracy and gay females with
58% accuracy. Those findings advance our understanding of the origins of
sexual orientation and the limits of human perception. Additionally,
given that companies and governments are increasingly using computer
vision algorithms to detect people’s intimate traits, our findings
expose a threat to the privacy and safety of gay men and women.</p>
</blockquote>
<ul>
<li>What is the proposed value of the algorithm?</li>
<li>What are the potential risks?</li>
<li>Are you supportive of this kind of research?</li>
</ul>
<p>A <a href="https://www.glaad.org/blog/glaad-and-hrc-call-stanford-university-responsible-media-debunk-dangerous-flawed-report" class="external-link">response
from GLAAD</a>, a leading LGBTQ media advocacy organization described
the work as dangerous and flawed. Meanwhile an <a href="https://blogs.scientificamerican.com/observations/can-we-read-a-persons-character-from-facial-images/" class="external-link">article
in Scientific American</a> notes that:</p>
<blockquote>
<p>This is precisely the kind of “scientific” claim that can motivate
repressive governments to apply AI algorithms to images of their
citizens. And what is it to stop them from “reading” intelligence,
political orientation and criminal inclinations from these images?</p>
</blockquote>
<!--

## Reflection.

TODO: there should be a reflection here. What is an appropriate task. What is an ethical consideration? Say a few words. Who makes the decision and based on what. REFLECTION. 1. Regulation 2. Social 3.

## Imitation

<!-- TODO:

https://economictimes.indiatimes.com/magazines/panache/deep-nostalgia-new-online-ai-tool-brings-portraits-of-dead-relatives-to-life-some-call-it-spooky/articleshow/81245242.cms?from=mdr

https://www.theverge.com/a/luka-artificial-intelligence-memorial-roman-mazurenko-bot

Deep fakes.

## Surveillance and privacy

<!-- TODO:

https://blogs.microsoft.com/on-the-issues/2018/12/06/facial-recognition-its-time-for-action/

https://www.nature.com/articles/d41586-020-03188-2

http://www.policingethicspanel.london/uploads/4/4/0/7/44076193/live_facial_recognition_final_report_may_2019.pdf

https://www.adalovelaceinstitute.org/report/beyond-face-value-public-attitudes-to-facial-recognition-technology/

https://blogs.microsoft.com/on-the-issues/2018/12/06/facial-recognition-its-time-for-action/

-->
<div id="keypoints1" class="callout keypoints">
<div class="callout-square">
<i class="callout-icon" data-feather="key"></i>
</div>
<div class="callout-inner">
<h3 class="callout-title">Key Points</h3>
<div class="callout-content">
<ul>
<li>Not all applications of machine learning are for the public
good.</li>
</ul>
</div>
</div>
</div>
</section></section><section id="aio-03-data"><p>Content from <a href="03-data.html">Data</a></p>
<hr>
<p>Last updated on 2024-11-14 |

        <a href="https://github.com/carpentries-incubator/machine-learning-responsible-python/edit/main/episodes/03-data.md" class="external-link">Edit this page <i aria-hidden="true" data-feather="edit"></i></a></p>
<p>Estimated time: <i aria-hidden="true" data-feather="clock"></i> 30 minutes</p>
<div class="text-end">
          <button role="button" aria-pressed="false" tabindex="0" id="expand-code" class="pull-right" data-expand="Expand All Solutions " data-collapse="Collapse All Solutions "> Expand All Solutions <i aria-hidden="true" data-feather="plus"></i></button>
        </div>
<div class="overview card">
<h2 class="card-header">Overview</h2>
<div class="row g-0">
<div class="col-md-4">
<div class="card-body">
<div class="inner">
<h3 class="card-title">Questions</h3>
<ul>
<li>How does data influence machine learning?</li>
<li>How can we better document data?</li>
</ul>
</div>
</div>
</div>
<div class="col-md-8">
<div class="card-body">
<div class="inner bordered">
<h3 class="card-title">Objectives</h3>
<ul>
<li>Recognise how data influences machine learning models.</li>
<li>Learn an approach for structured documention of data
characteristics.</li>
</ul>
</div>
</div>
</div>
</div>
</div>
<section><h2 class="section-heading" id="data-as-a-foundation">Data as a foundation<a class="anchor" aria-label="anchor" href="#data-as-a-foundation"></a>
</h2>
<hr class="half-width">
<!--
Should cover data representativeness: https://www.nature.com/articles/s41746-021-00549-7

TODO: briefly mention the SSI work on FAIR etc.
--><p>Data is crucial for the field of machine learning and it forms the
foundation for the models that we build and use. When data is made
available to the machine learning community, it has the ability to drive
progress and shape the direction of research.</p>
<p>Lack of available data, meanwhile, stifles and stalls progress.
Despite the importance of data, its creation and sharing has often been
relegated to footnotes in machine learning studies, seen as secondary to
the work of model building and application.</p>
</section><section><h2 class="section-heading" id="the-data-landscape">The data landscape<a class="anchor" aria-label="anchor" href="#the-data-landscape"></a>
</h2>
<hr class="half-width">
<p>To enable the creation of more powerful machine learning models,
there have been increasing efforts to create larger and larger datasets
to train the models. In many cases, little thought has seemingly gone
into the creation of these datasets.</p>
<p>In <strong><a href="https://arxiv.org/pdf/2012.05345.pdf" class="external-link">Data and
its (dis)contents: A survey of dataset development and use in machine
learning research</a></strong>, Paullada et al survey the research
literature to explore how data has influenced the field of machine
learning. Broadly, topics discussed include:</p>
<ul>
<li>Issues of representation, such as “glaring under-representation of
darker skinned subjects … within prominent facial analysis
datasets”</li>
<li>Propensity of models to make performance gains on datasets through
“cheap tricks” that do not extrapolate well to out-of-distribution
data.</li>
<li>Risks of datasets in legitimizing problematic goals, such as the
prediction of sexual preferences using social media photographs.</li>
<li>Failure to recognize human annotation work as <em>interpretive
work</em> that encodes subjective values and judgments, resulting in a
conflation of “gold labels” with ground truth.</li>
<li>Management and distribution of data, especially as it relates to
privacy and risk of exploitation.</li>
</ul>
<p>A 2021 study by <a href="https://arxiv.org/abs/2110.01963" class="external-link">Birhane
and colleagues</a> explored the LAION dataset, a huge dataset scraped
from the internet that is often used as a source for training large
language and imaging models.</p>
<figure><img src="../fig/bad_data.png" alt="CommonCrawl" class="figure mx-auto d-block"></figure></section><section><h2 class="section-heading" id="machine-learning-during-the-pandemic">Machine learning during the pandemic<a class="anchor" aria-label="anchor" href="#machine-learning-during-the-pandemic"></a>
</h2>
<hr class="half-width">
<p>When COVID-19 hit Europe in 2020, machine learning researchers around
the world turned their focus to building predictive models to help beat
the pandemic. Despite these efforts, <a href="https://www.turing.ac.uk/sites/default/files/2021-06/data-science-and-ai-in-the-age-of-covid_full-report_2.pdf" class="external-link">an
inquiry by The Turing Institute</a> concluded none of the models made a
real difference, and some were potentially harmful.</p>
<div id="exercise" class="callout challenge">
<div class="callout-square">
<i class="callout-icon" data-feather="zap"></i>
</div>
<div id="exercise" class="callout-inner">
<h3 class="callout-title">Exercise</h3>
<div class="callout-content">
<p>Look at this report published in the <a href="https://www.technologyreview.com/2021/07/30/1030329/machine-learning-ai-failed-covid-hospital-diagnosis-pandemic/" class="external-link">MIT
Technology Review</a> that summarises the findings of the Turing
Institute.</p>
<ol style="list-style-type: upper-alpha">
<li>What were some of the causes of failure, according to the article in
the MIT Technology Review? (“What went wrong?”).<br>
</li>
<li>What solutions are suggested in the article? (“How to fix
it?”).</li>
</ol>
</div>
</div>
</div>
<div id="accordionSolution1" class="accordion challenge-accordion accordion-flush">
<div class="accordion-item">
<button class="accordion-button solution-button collapsed" type="button" data-bs-toggle="collapse" data-bs-target="#collapseSolution1" aria-expanded="false" aria-controls="collapseSolution1">
  <h4 class="accordion-header" id="headingSolution1"> Show me the solution </h4>
</button>
<div id="collapseSolution1" class="accordion-collapse collapse" aria-labelledby="headingSolution1" data-bs-parent="#accordionSolution1">
<div class="accordion-body">
<ol style="list-style-type: upper-alpha">
<li>Poor quality data. “Many unwittingly used a data set that contained
chest scans of children who did not have covid as their examples of what
non-covid cases looked like. But as a result, the AIs learned to
identify kids, not covid.”</li>
</ol>
<p>“Driggs’s group trained its own model using a data set that contained
a mix of scans taken when patients were lying down and standing up.
Because patients scanned while lying down were more likely to be
seriously ill, the AI learned wrongly to predict serious covid risk from
a person’s position.”</p>
<p>“In yet other cases, some AIs were found to be picking up on the text
font that certain hospitals used to label the scans. As a result, fonts
from hospitals with more serious caseloads became predictors of covid
risk.”</p>
<p>“A more subtle problem Driggs highlights is incorporation bias, or
bias introduced at the point a data set is labeled. For example, many
medical scans were labeled according to whether the radiologists who
created them said they showed covid. But that embeds, or incorporates,
any biases of that particular doctor into the ground truth of a data
set.”</p>
<ol start="2" style="list-style-type: upper-alpha">
<li>“Researchers also need to share their models and disclose how they
were trained so that others can test them and build on them.”Those are
two things we could do today,” he says. “And they would solve maybe 50%
of the issues that we identified.”</li>
</ol>
<p>“If all these people making new models instead tested models that
were already available, maybe we’d have something that could really help
in the clinic by now.”</p>
</div>
</div>
</div>
</div>
</section><section><h2 class="section-heading" id="data-documentation">Data documentation<a class="anchor" aria-label="anchor" href="#data-documentation"></a>
</h2>
<hr class="half-width">
<p>Given the fundamental role of data in machine learning, there have
been calls for data sharers to provide better documention for the
downstream consumers.</p>
<p>The Conference on Neural Information Processing Systems, for example,
introduced a <a href="https://neuripsconf.medium.com/announcing-the-neurips-2021-datasets-and-benchmarks-track-644e27c1e66c" class="external-link">Dataset
Track</a> for the first time in 2021 to encourage reporting “on highly
valuable machine learning datasets and benchmarks” … and to create a
forum to discuss “how to improve dataset development”.</p>
<p>In <a href="https://arxiv.org/pdf/1803.09010.pdf" class="external-link">Datasheets for
Datasets</a>, Gebru et al call for data creators to provide “datasheets”
to accompany the datasets that they share. The datasheets serve dual
purposes: for the creator they encourage reflection on the data creation
and distribution process, and for the consumer they offer details
necessary to make informed decisions about using a dataset</p>
<blockquote>
<p>“We propose that every dataset be accompanied with a datasheet that
documents its motivation, composition, collection process, recommended
uses, and so on. Datasheets for datasets have the potential to increase
transparency and accountability within the machine learning community,
mitigate unwanted societal biases in machine learning models, facilitate
greater reproducibility of machine learning results, and help
researchers and practitioners to select more appropriate datasets for
their chosen tasks</p>
</blockquote>
<div id="exercise-1" class="callout challenge">
<div class="callout-square">
<i class="callout-icon" data-feather="zap"></i>
</div>
<div id="exercise-1" class="callout-inner">
<h3 class="callout-title">Exercise</h3>
<div class="callout-content">
<p>Look at Appendix A of <a href="https://arxiv.org/pdf/1803.09010.pdf" class="external-link">Datasheets for
Datasets</a>.</p>
<p>What sections are included in the example datasheet? What do these
sections seek to capture?</p>
</div>
</div>
</div>
<div id="accordionSolution2" class="accordion challenge-accordion accordion-flush">
<div class="accordion-item">
<button class="accordion-button solution-button collapsed" type="button" data-bs-toggle="collapse" data-bs-target="#collapseSolution2" aria-expanded="false" aria-controls="collapseSolution2">
  <h4 class="accordion-header" id="headingSolution2"> Show me the solution </h4>
</button>
<div id="collapseSolution2" class="accordion-collapse collapse" aria-labelledby="headingSolution2" data-bs-parent="#accordionSolution2">
<div class="accordion-body">
<ul>
<li>Motivation</li>
<li>Composition</li>
<li>Collection Process</li>
<li>Preprocessing/cleaning/labeling</li>
<li>Uses</li>
<li>Distribution</li>
<li>Maintenance</li>
</ul>
</div>
</div>
</div>
</div>
<div id="keypoints1" class="callout keypoints">
<div class="callout-square">
<i class="callout-icon" data-feather="key"></i>
</div>
<div class="callout-inner">
<h3 class="callout-title">Key Points</h3>
<div class="callout-content">
<ul>
<li>Data is fundamental to the field of machine learning.</li>
<li>Datasheets can help us to reflect on the process of data creation
and distribution.</li>
</ul>
</div>
</div>
</div>
</section></section><section id="aio-04-bias"><p>Content from <a href="04-bias.html">Fairness</a></p>
<hr>
<p>Last updated on 2024-11-14 |

        <a href="https://github.com/carpentries-incubator/machine-learning-responsible-python/edit/main/episodes/04-bias.md" class="external-link">Edit this page <i aria-hidden="true" data-feather="edit"></i></a></p>
<p>Estimated time: <i aria-hidden="true" data-feather="clock"></i> 30 minutes</p>
<div class="text-end">
          <button role="button" aria-pressed="false" tabindex="0" id="expand-code" class="pull-right" data-expand="Expand All Solutions " data-collapse="Collapse All Solutions "> Expand All Solutions <i aria-hidden="true" data-feather="plus"></i></button>
        </div>
<div class="overview card">
<h2 class="card-header">Overview</h2>
<div class="row g-0">
<div class="col-md-4">
<div class="card-body">
<div class="inner">
<h3 class="card-title">Questions</h3>
<ul>
<li>What do we mean by fairness and bias?</li>
<li>What are some examples of biased models?</li>
</ul>
</div>
</div>
</div>
<div class="col-md-8">
<div class="card-body">
<div class="inner bordered">
<h3 class="card-title">Objectives</h3>
<ul>
<li>Consider sources of bias in data.</li>
<li>Recognise examples of bias in language models.</li>
<li>Recognise examples of bias in image models.</li>
</ul>
</div>
</div>
</div>
</div>
</div>
<section><h2 class="section-heading" id="bias-and-fairness">Bias and fairness<a class="anchor" aria-label="anchor" href="#bias-and-fairness"></a>
</h2>
<hr class="half-width">
<!--

See: https://www.nature.com/articles/s41746-021-00549-7 Box 2 on algorithmic bias.
--><p>We live in a world full of bias. Opportunities such as education and
healthcare are not evenly distributed: access is largely a matter of
luck and a reflection of our circumstances of birth. Given the uneven,
biased world we live in, it is hardly surprising that the machine
learning models that we build are highly susceptible to exhibiting
favoritism and prejudice.</p>
<p>Bias is a systematic preference or prejudice against a particular
group, individual, or feature. A <a href="https://arxiv.org/pdf/1908.09635.pdf" class="external-link">well-cited definition of
fairness is</a> “the absence of any prejudice or favoritism towards an
individual or a group based on their inherent or acquired
characteristics”.</p>
<p>Machine learning models are increasingly used in ways that directly
affect people’s lives, so it is crucially important that we strive for
fairness to prevent harmful discrimination.</p>
<p>Strategies to achieve fairness often focus on attempting to eliminate
bias in training data (for example, by collecting more representative
datasets) or by making algorithmic adjustments (for example, by
weighting underrepresented classes more heavily). This remains an active
research area, wth no simple solutions.</p>
</section><section><h2 class="section-heading" id="photo-upsampling">Photo upsampling<a class="anchor" aria-label="anchor" href="#photo-upsampling"></a>
</h2>
<hr class="half-width">
<p>Biases are often most obvious in imaging models. In <a href="https://arxiv.org/pdf/2003.03808.pdf" class="external-link">their paper</a> on “PULSE:
Self-Supervised Photo Upsampling via Latent Space Exploration of
Generative Models”, Menon and colleagues describe the application of a
machine learning algorithm for upsampling images.</p>
<p>The paper demonstrates how a blurry, low resolution image can be
transformed into a “sharp, realistic, high-resolution image”. Soon after
publication, apparent biases were <a href="https://twitter.com/Chicken3gg/status/1274314622447820801?s=20&amp;t=_oORPJBJRaBW_J0zresFJQ" class="external-link">shared
widely on social media</a>.</p>
<div id="question" class="callout challenge">
<div class="callout-square">
<i class="callout-icon" data-feather="zap"></i>
</div>
<div id="question" class="callout-inner">
<h3 class="callout-title">Question</h3>
<div class="callout-content">
<ol style="list-style-type: upper-alpha">
<li>Who is shown in this blurred picture? <img src="../fig/pulse_chicken3gg_original.png" alt="Barack Obama by @Chicken3gg, Twitter" class="figure">
</li>
</ol>
</div>
</div>
</div>
<div id="accordionSolution1" class="accordion challenge-accordion accordion-flush">
<div class="accordion-item">
<button class="accordion-button solution-button collapsed" type="button" data-bs-toggle="collapse" data-bs-target="#collapseSolution1" aria-expanded="false" aria-controls="collapseSolution1">
  <h4 class="accordion-header" id="headingSolution1">
  Answer
  </h4>
</button>
<div id="collapseSolution1" class="accordion-collapse collapse" data-bs-parent="#accordionSolution1" aria-labelledby="headingSolution1">
<div class="accordion-body">
<ol style="list-style-type: upper-alpha">
<li>While the picture is of Barack Obama, the upsampled image shows a
white face. <img src="../fig/pulse_chicken3gg_result.png" alt="Barack Obama by @Chicken3gg, Twitter" class="figure">
</li>
</ol>
</div>
</div>
</div>
</div>
<p>Menon and colleagues subsequently updated their paper to discuss this
issue of bias. They assert that the problems inherent in the PULSE model
are largely a result of the <a href="https://arxiv.org/abs/1812.04948" class="external-link">underlying StyleGAN model</a>,
which they had used in their work.</p>
<blockquote>
<p>Overall, it seems that sampling from StyleGAN yields white faces much
more frequently than faces of people of color … This bias extends to any
downstream application of StyleGAN, including the implementation of
PULSE using StyleGAN.</p>
<p>…</p>
<p>Results indicate a racial bias among the generated pictures, with
close to three-fourths (72.6%) of the pictures representing White
people. Asian (13.8%) and Black (10.1%) are considerably less frequent,
while Indians represent only a minor fraction of the pictures
(3.4%).</p>
</blockquote>
<p>You can <a href="https://colab.research.google.com/github/tg-bomze/Face-Depixelizer/blob/master/Face_Depixelizer_Eng.ipynb#scrollTo=fU0aGtD4Nl4W" class="external-link">try
the model here</a>.</p>
</section><section><h2 class="section-heading" id="language-models">Language models<a class="anchor" aria-label="anchor" href="#language-models"></a>
</h2>
<hr class="half-width">
<p>Natural Language Processing (NLP) is an area of machine learning
focused on the analysis of text. NLP has numerous practical
applications, including voice recognition, foreign-language translation,
and even <a href="https://copilot.github.com/" class="external-link">AI pair
programming</a>.</p>
<p>In recent years, some of the major advances in NLP have been in the
evolution of models that allow tokens (words, characters) in text
sequences to be predicted from their context. Two such models include
Bidirectional Encoder Representations from Transformers (BERT) and
Generative Pre-trained Transformer (GPT).</p>
<p>These language models are built upon “word embeddings”, which are
representations of words in a multi-dimensional space. The models
implement a concept popularized by linguist John Firth that “a word is
characterized by the company it keeps”.</p>
<p>When the models are trained on biased data - which they inevitably
are - the models become amplifiers of often harmful sterotypes. This
issue, and a proposed approach to their mitigation, are discussed by
Bolukbasi et al in <a href="https://arxiv.org/pdf/1607.06520.pdf" class="external-link">Man is
to Computer Programmer as Woman is to Homemaker? Debiasing Word
Embeddings</a>.</p>
<blockquote>
<p>The blind application of machine learning runs the risk of amplifying
biases present in data. Such a danger is facing us with word embedding,
a popular framework to represent text data as vectors which has been
used in many machine learning and natural language processing tasks. We
show that even word embeddings trained on Google News articles exhibit
female/male gender stereotypes to a disturbing extent.</p>
<p>…</p>
<p>given an analogy puzzle, “man is to king as woman is to x” (denoted
as man:king :: woman:x), simple arithmetic of the embedding vectors
finds that x=queen is the best answer because:</p>
<p><span class="math display">\[
\overrightarrow{man} - \overrightarrow{woman} \approx
\overrightarrow{king} − \overrightarrow{queen}
\]</span></p>
<p>…</p>
<p>… the same system that solved the above reasonable analogies will
offensively answer “man is to computer programmer as woman is to x” with
x=homemaker. Similarly, it outputs that a father is to a doctor as a
mother is to a nurse.</p>
</blockquote>
</section><section><h2 class="section-heading" id="stochastic-parrots">Stochastic parrots<a class="anchor" aria-label="anchor" href="#stochastic-parrots"></a>
</h2>
<hr class="half-width">
<p>In their high-profile paper <a href="https://dl.acm.org/doi/pdf/10.1145/3442188.3445922" class="external-link">On the Dangers
of Stochastic Parrots: Can Language Models Be Too Big?</a>, Bender and
colleagues ask: “What are the possible risks associated with [language
model] technology and what paths are available for mitigating those
risks?”.</p>
<p>The last couple of paragraphs of the conclusion are copied below:</p>
<blockquote>
<p>Work on synthetic human behavior is a bright line in ethical AI
development, where downstream effects need to be understood and modeled
in order to block foreseeable harm to society and different social
groups. Thus what is also needed is scholarship on the benefits, harms,
and risks of mimicking humans and thoughtful design of target tasks
grounded in use cases sufficiently concrete to allow collaborative
design with affected communities.</p>
</blockquote>
<div id="question-1" class="callout challenge">
<div class="callout-square">
<i class="callout-icon" data-feather="zap"></i>
</div>
<div id="question-1" class="callout-inner">
<h3 class="callout-title">Question</h3>
<div class="callout-content">
<ol style="list-style-type: upper-alpha">
<li>Why is the word “parrot” used to describe the language models?</li>
</ol>
</div>
</div>
</div>
<div id="accordionSolution2" class="accordion challenge-accordion accordion-flush">
<div class="accordion-item">
<button class="accordion-button solution-button collapsed" type="button" data-bs-toggle="collapse" data-bs-target="#collapseSolution2" aria-expanded="false" aria-controls="collapseSolution2">
  <h4 class="accordion-header" id="headingSolution2">
  Answer
  </h4>
</button>
<div id="collapseSolution2" class="accordion-collapse collapse" data-bs-parent="#accordionSolution2" aria-labelledby="headingSolution2">
<div class="accordion-body">
<ol style="list-style-type: upper-alpha">
<li>On a surface level modern language models can give the appearance of
possessing human-like intelligence, for example, by holding
conversations or by creating poems. In reality, the models are simply
mimicking the language and biases of humans.</li>
</ol>
</div>
</div>
</div>
</div>
<!--

# Biased labels

TODO:

Jury learning: https://arxiv.org/abs/2202.02950

-->
<div id="keypoints1" class="callout keypoints">
<div class="callout-square">
<i class="callout-icon" data-feather="key"></i>
</div>
<div class="callout-inner">
<h3 class="callout-title">Key Points</h3>
<div class="callout-content">
<ul>
<li>Biases in data lead to biased models.</li>
<li>All current models are likely to exhibit some form of bias.</li>
<li>Achieving fairness is an increasingly active area of research.</li>
</ul>
</div>
</div>
</div>
</section></section><section id="aio-05-shift"><p>Content from <a href="05-shift.html">Dataset shift</a></p>
<hr>
<p>Last updated on 2024-11-14 |

        <a href="https://github.com/carpentries-incubator/machine-learning-responsible-python/edit/main/episodes/05-shift.md" class="external-link">Edit this page <i aria-hidden="true" data-feather="edit"></i></a></p>
<p>Estimated time: <i aria-hidden="true" data-feather="clock"></i> 30 minutes</p>
<div class="text-end">
          <button role="button" aria-pressed="false" tabindex="0" id="expand-code" class="pull-right" data-expand="Expand All Solutions " data-collapse="Collapse All Solutions "> Expand All Solutions <i aria-hidden="true" data-feather="plus"></i></button>
        </div>
<div class="overview card">
<h2 class="card-header">Overview</h2>
<div class="row g-0">
<div class="col-md-4">
<div class="card-body">
<div class="inner">
<h3 class="card-title">Questions</h3>
<ul>
<li>What is dataset shift?</li>
<li>What are examples of dataset shift?</li>
<li>What are the implications of dataset shift?</li>
</ul>
</div>
</div>
</div>
<div class="col-md-8">
<div class="card-body">
<div class="inner bordered">
<h3 class="card-title">Objectives</h3>
<ul>
<li>Recognise causes of dataset shift.</li>
<li>Understand the potential outcomes of dataset shift.</li>
</ul>
</div>
</div>
</div>
</div>
</div>
<section><h2 class="section-heading" id="dataset-shift">Dataset shift<a class="anchor" aria-label="anchor" href="#dataset-shift"></a>
</h2>
<hr class="half-width">
<p>Machine learning models often face major challenges when applied in
real-life settings. The tightly-controlled conditions under which models
are trained are often very different to conditions “in the wild”.
Dataset shift is a term that is used to describe the nature of changing
data conditions in the context of machine learning.</p>
<p>In their paper on <a href="https://www.nejm.org/doi/full/10.1056/NEJMc2104626" class="external-link">The Clinician
and Dataset Shift in Artificial Intelligence</a>, Finlayson et al
explore different causes of dataset shift within hospitals, suggesting
policies for recognising these changes as well as strategies for
mitigation.</p>
<p>While the article itself is paywalled, there is an <a href="https://sgfin.github.io/assets/dataset_shift/NEJM_DS_Supplement.pdf" class="external-link">openly
available summary</a> of the key points raised in the article. The
authors suggest that dataset shift occurs in a clinical setting as a
result of three broad categories of change: Changes in Technology;
Changes in Population and Setting; and Changes in Behavior.</p>
<!-- - Changes in Technology: for example, introduction of a new data acquisition device.
- Changes in Population and Setting: for example, a change in patient demographics.
- Changes in Behavior: for example, a change in clinical practice. -->
</section><section><h2 class="section-heading" id="changes-in-technology">Changes in technology<a class="anchor" aria-label="anchor" href="#changes-in-technology"></a>
</h2>
<hr class="half-width">
<p>The International Classification of Diseases (ICD) system is a
globally used set of disease codes maintained by the World Health
Organisation (WHO), revised periodically. When revisions are
introducted, this can affect the clinical prediction models that are
built upon them.</p>
<p>For example, <a href="https://jamanetwork.com/journals/jamanetworkopen/fullarticle/2764197" class="external-link">study
that examined insurance claims</a> for &gt;18 million adults and
children in the US from 2010 to 2017 found that the transition from
ICD-9 to ICD-11 led to instantaneous increases or decreases of 20% or
more in the prevalence of many diagnostic categories.</p>
<p>Finlayson and colleagues suggest that fixing such an issue might
require mapping of concepts, or even retraining of models. Referring to
the <a href="https://sgfin.github.io/assets/dataset_shift/NEJM_DS_Supplement.pdf" class="external-link">Finlayson
paper</a>, what is is another example of a technology change that might
lead to dataset shift, and how might it be addressed?</p>
</section><section><h2 class="section-heading" id="changes-in-population-and-setting">Changes in population and setting<a class="anchor" aria-label="anchor" href="#changes-in-population-and-setting"></a>
</h2>
<hr class="half-width">
<p>In <a href="https://gking.harvard.edu/files/gking/files/0314policyforumff.pdf" class="external-link">The
Parable of Google Flu: Traps in Big Data Analysis</a> Lazer and
colleagues discuss Google Flu Trends, a product developed to predict
U.S. flu burden:</p>
<blockquote>
<p>The initial version of GFT was a particularly problematic marriage of
big and small data. Essentially, the methodology was to find the best
matches among 50 million search terms to fit 1152 data points. The odds
of finding search terms that match the propensity of the flu but are
structurally unrelated, and so do not predict the future, were quite
high. GFT developers, in fact, report weeding out seasonal search terms
unrelated to the flu but strongly correlated to the CDC data, such as
those regarding high school basketball. This should have been a warning
that the big data were overfitting the small number of cases — a
standard concern in data analysis. This ad hoc method of throwing out
peculiar search terms failed when GFT completely missed the nonseasonal
2009 influenza A–H1N1 pandemic. In short, the initial version of GFT was
part flu detector, part winter detector.</p>
</blockquote>
<p>Looking again a the <a href="https://sgfin.github.io/assets/dataset_shift/NEJM_DS_Supplement.pdf" class="external-link">Finlayson
paper</a>, what is another example of a change in population or setting
that could affect the performance of a model? How might the effects of
this change be mitigated?</p>
</section><section><h2 class="section-heading" id="changes-in-behaviour">Changes in behaviour<a class="anchor" aria-label="anchor" href="#changes-in-behaviour"></a>
</h2>
<hr class="half-width">
<p>Laboratory tests are often important predictors in clinical models.
<a href="https://www.bmj.com/content/361/bmj.k1479" class="external-link">Research has
found</a> that in many cases the timing of laboratory tests is as
important, or more important, than the results of the tests
themselves:</p>
<blockquote>
<p>The presence of a laboratory test order, regardless of any other
information about the test result, has a significant association
(P&lt;0.001) with the odds of survival in 233 of 272 (86%) tests. Data
about the timing of when laboratory tests were ordered were more
accurate than the test results in predicting survival in 118 of 174
tests (68%).</p>
</blockquote>
<p>Minor changes in clinical practice - for example, a change in the
routine of ordering a particular laboratory test - may therefore have
unintended side-effects in terms of the performance of machine learning
models trainined on laboratory data.</p>
<div id="keypoints1" class="callout keypoints">
<div class="callout-square">
<i class="callout-icon" data-feather="key"></i>
</div>
<div class="callout-inner">
<h3 class="callout-title">Key Points</h3>
<div class="callout-content">
<ul>
<li>Dataset shift can result from changes in technology, population, and
behaviour.</li>
<li>Dataset shift can lead to deterioration of models after
deployment.</li>
<li>Dataset shift is a major issue in terms of deployment of machine
learning models.</li>
</ul>
</div>
</div>
</div>
</section></section><section id="aio-06-explainability"><p>Content from <a href="06-explainability.html">Explainability</a></p>
<hr>
<p>Last updated on 2024-11-14 |

        <a href="https://github.com/carpentries-incubator/machine-learning-responsible-python/edit/main/episodes/06-explainability.md" class="external-link">Edit this page <i aria-hidden="true" data-feather="edit"></i></a></p>
<p>Estimated time: <i aria-hidden="true" data-feather="clock"></i> 30 minutes</p>
<div class="text-end">
          <button role="button" aria-pressed="false" tabindex="0" id="expand-code" class="pull-right" data-expand="Expand All Solutions " data-collapse="Collapse All Solutions "> Expand All Solutions <i aria-hidden="true" data-feather="plus"></i></button>
        </div>
<div class="overview card">
<h2 class="card-header">Overview</h2>
<div class="row g-0">
<div class="col-md-4">
<div class="card-body">
<div class="inner">
<h3 class="card-title">Questions</h3>
<ul>
<li>“What is explainability?”</li>
<li>“Is explainability necessary?”</li>
</ul>
</div>
</div>
</div>
<div class="col-md-8">
<div class="card-body">
<div class="inner bordered">
<h3 class="card-title">Objectives</h3>
<ul>
<li>“Understand the concepts of explainability and
interpretability.”</li>
<li>“Understand how saliency maps can help us to explain a model.”</li>
</ul>
</div>
</div>
</div>
</div>
</div>
<section><h2 class="section-heading" id="interpretability-and-explainability">Interpretability and explainability<a class="anchor" aria-label="anchor" href="#interpretability-and-explainability"></a>
</h2>
<hr class="half-width">
<p>“Interpretable” and “explainable” are terms that are often used
interchangeably to describe the characteristic of a machine learning
model to be understood. In recent literature, however, interpretable is
perhaps more often used to refer to models with limited complexity and
predictable behaviour. For example, a decision tree may be inherently
interpretable:</p>
<figure><img src="../fig/decision-tree.png" alt="Decision tree and boundaries." class="figure mx-auto d-block"><div class="figcaption">Decision tree and boundaries.</div>
</figure><p>If we can look at our model and predict what will happen to our
prediction if input values change, then we can say that the model is
interpretable. Often, however, data and models are too complex and
high-dimensional to be easily understood. They cannot be explained by a
simple relationship between inputs and outputs.</p>
<p>For these complex models there is typically a focus on attempting to
dissect the model’s decision making procedure. This insights lead us to
explainability: our ability to gaze into a complex model and explain its
behaviour.</p>
</section><section><h2 class="section-heading" id="the-necessity-of-interpretability-and-explainability">The necessity of interpretability and explainability<a class="anchor" aria-label="anchor" href="#the-necessity-of-interpretability-and-explainability"></a>
</h2>
<hr class="half-width">
<p>If a model is making a prediction, many of us would like to know how
the decision was reached. With this understanding, we gain trust. <a href="https://arxiv.org/pdf/1702.08608.pdf" class="external-link">Doshi-Velez and Kim</a>
suggest that interpretablity (/explainablity) can assist in ascertaining
presence of desired features such as fairness, privacy, reliability,
robustness, causality, usability and trust:</p>
<ul>
<li>Fairness: that groups are not discriminated against.</li>
<li>Privacy: that sensitive information is not revealed.</li>
<li>Reliability and robustness: that models reach certain levels of
performance despite parameter or input variation.</li>
<li>Causality: that predicted changes in output due to a perturbation
will occur as expected.</li>
<li>Usability: that methods provide information that assist users to
accomplish a task.</li>
</ul>
<p>In machine learning in health, it has been argued that explainable AI
is necessary to gain trust with the health-care workforce, provide
transparency into decision making processes, and to mitigate bias. As a
counterpoint, <a href="https://doi.org/10.1016/S2589-7500(21)00208-9" class="external-link">Ghassemi and
colleagues</a> argue that urrent explainability methods are unlikely to
achieve these goals for patient-level decision support.</p>
<p>Instead, they advocate for “rigorous internal and external validation
of AI models as a more direct means of achieving the goals often
associated with explainability”, and “caution against having
explainability be a requirement for clinically deployed models”.</p>
</section><section><h2 class="section-heading" id="saliency-maps">Saliency maps<a class="anchor" aria-label="anchor" href="#saliency-maps"></a>
</h2>
<hr class="half-width">
<p>Saliency maps - and related approaches - are popular form of
explainability for imaging models. Saliency maps use color to illustrate
the extent to which a region of an image contributes to a given
decision. For example, when building neural network models to predict
lung conditions (pleural effusion) we can see the model pays particular
attention to certain areas of an image.</p>
<figure><img src="../fig/saliency.png" alt="Saliency map for chest X-ray model" class="figure mx-auto d-block"><div class="figcaption">Saliency map for chest X-ray model</div>
</figure><p>While saliency maps may be useful, they are also <a href="https://arxiv.org/abs/1810.03292" class="external-link">known to be problematic</a> in
many cases. Displaying a region of importance leaves us to decide what
the explanation might be. The human tendency is to assume that the
feature we would find important is the one that was used (this is an
example of a famously harmful cognitive error called confirmation
bias).</p>
<p>This problem is well summarised by computer scientist Cynthia Rudin:
“You could have many explanations for what a complex model is doing. Do
you just pick the one you ‘want’ to be correct? The ability of
localisation methods to mislead human users is compellingly demonstrated
by <a href="https://arxiv.org/abs/1810.03292" class="external-link">Adebayo and
colleagues</a>, who show that even untrained networks can produce
saliency maps that appear reassuring.</p>
<!--  TODO:

## Shapley values

In "Stop Explaining Black Box Machine Learning Models for High Stakes Decisions and Use Interpretable Models Instead", Cynthia Rudin

These concerns also extend to other well known post-hoc explanation methods such as locally interpretable model-agnostic explanations (LIME)27 and Shapley values (SHAP).28 LIME seeks to understand decisions at the individual level by permuting the input example (altering it in minor ways) and identifying which alterations were most likely to change the decision. In the case of image analysis, this is done by occluding parts of the image, the explanation consisting of a heat map that indicates the image components that were most important for the decision. Such explanations suffer from interpretability gaps in the same way as saliency mapping. Methods such as LIME and SHAP are generic and not specific to images and are routinely used on a wide variety of health-care data, including structured data from electronic health-care records29 and electroencephalogram waveform data.30

-->
</section><section><h2 class="section-heading" id="explainability-of-machine-learning-models">Explainability of machine learning models<a class="anchor" aria-label="anchor" href="#explainability-of-machine-learning-models"></a>
</h2>
<hr class="half-width">
<p>The requirement for explainability is even making its way into legal
governance. The European Union General Data Protection (GDPR)) for
example, states that “[the data subject should have] the right … to
obtain an explanation of the decision reached”.</p>
<p>If our doctor or nurse recommends paracetamol (acetaminophen) for
pain management, most of us would accept the suggestion without
question. This is despite the action of paracetamol at a molecular level
<a href="https://pubmed.ncbi.nlm.nih.gov/15662292/" class="external-link">being unclear</a>.
Are we holding machine learning models to a higher standard than
humans?</p>
<div id="keypoints1" class="callout keypoints">
<div class="callout-square">
<i class="callout-icon" data-feather="key"></i>
</div>
<div class="callout-inner">
<h3 class="callout-title">Key Points</h3>
<div class="callout-content">
<ul>
<li>“The importance of explainability is a matter of debate.”</li>
<li>“Saliency maps highlight regions of data that most strongly
contributed to a decision.”</li>
</ul>
</div>
</div>
</div>
</section></section><section id="aio-07-attacks"><p>Content from <a href="07-attacks.html">Attacks</a></p>
<hr>
<p>Last updated on 2024-11-14 |

        <a href="https://github.com/carpentries-incubator/machine-learning-responsible-python/edit/main/episodes/07-attacks.md" class="external-link">Edit this page <i aria-hidden="true" data-feather="edit"></i></a></p>
<p>Estimated time: <i aria-hidden="true" data-feather="clock"></i> 30 minutes</p>
<div class="text-end">
          <button role="button" aria-pressed="false" tabindex="0" id="expand-code" class="pull-right" data-expand="Expand All Solutions " data-collapse="Collapse All Solutions "> Expand All Solutions <i aria-hidden="true" data-feather="plus"></i></button>
        </div>
<div class="overview card">
<h2 class="card-header">Overview</h2>
<div class="row g-0">
<div class="col-md-4">
<div class="card-body">
<div class="inner">
<h3 class="card-title">Questions</h3>
<ul>
<li>How can models be intentionally mislead?</li>
</ul>
</div>
</div>
</div>
<div class="col-md-8">
<div class="card-body">
<div class="inner bordered">
<h3 class="card-title">Objectives</h3>
<ul>
<li>Understand the concept of adversarial attacks.</li>
</ul>
</div>
</div>
</div>
</div>
</div>
<section><h2 class="section-heading" id="manipulation-of-models">Manipulation of models<a class="anchor" aria-label="anchor" href="#manipulation-of-models"></a>
</h2>
<hr class="half-width">
<p>It is important to be aware that models are susceptible to
manipulation by targeted attacks. A model is susceptible to attack if it
can be manipulated to produce an unexpected output. Currently most
examples of models being mislead are theoretical - and often humourous -
but this is likely to change as the stakes increase. These examples also
demonstrate the fragility of models. It is not difficult to see how an
algorithm-led system could reach an incorrect decision simply due to an
unusual event.</p>
</section><section><h2 class="section-heading" id="adversarial-attacks">Adversarial attacks<a class="anchor" aria-label="anchor" href="#adversarial-attacks"></a>
</h2>
<hr class="half-width">
<p>One common method for attack is to alter input data to intentionally
cause misclassification. Researchers at Google, for example,
demonstrated that they could generate a sticker that could <a href="https://slate.com/technology/2018/01/google-researchers-tricked-an-a-i-into-thinking-a-banana-was-a-toaster.html" class="external-link">trick
a machine learning model</a> into confusing a picture of a banana with a
toaster.</p>
<figure><img src="../fig/banana.png" alt="Banana or toaster" width="800" class="figure mx-auto d-block"></figure><p>While the “adversarial patch” requires significant effort to fool the
algorithm, researchers at OpenAI discovered that their image
classification model could be fooled by nothing more than a pen and
paper. They announced that a model that they had developed for
classifying images would “respond to the same concept whether presented
literally, symbolically, or conceptually. As a result, they demonstrated
some <a href="https://www.theguardian.com/technology/2021/mar/08/typographic-attack-pen-paper-fool-ai-thinking-apple-ipod-clip" class="external-link">surprising
results</a> in the application of the model.</p>
<figure><img src="../fig/poodle.png" alt="poodle" width="800" class="figure mx-auto d-block"></figure><figure><img src="../fig/apple.png" alt="apple" width="800" class="figure mx-auto d-block"></figure><!--

Data can be overlaid with targeted values that lead to misclassification.

https://www.science.org/doi/10.1126/science.aaw4399

https://arxiv.org/abs/1804.05296

Examples, and discussion.



https://twitter.com/MIT_CSAIL/status/1507754751995260931

https://slate.com/technology/2018/01/google-researchers-tricked-an-a-i-into-thinking-a-banana-was-a-toaster.html

https://www.theguardian.com/technology/2021/mar/08/typographic-attack-pen-paper-fool-ai-thinking-apple-ipod-clip


https://kde.mitre.org/blog/2018/10/28/is-this-a-wolf-understanding-bias-in-machine-learning/

https://arxiv.org/abs/1804.05296


TODO:

Look at 4 in https://arxiv.org/pdf/2012.05345.pdf



## Data injection

TODO:

Where models are continuously trained, there is risk that new training data might be intentionally injected in order to achieve a desired outcome.

--><div id="keypoints1" class="callout keypoints">
<div class="callout-square">
<i class="callout-icon" data-feather="key"></i>
</div>
<div class="callout-inner">
<h3 class="callout-title">Key Points</h3>
<div class="callout-content">
<ul>
<li>Models are susceptible to manipulation.</li>
</ul>
</div>
</div>
</div>
</section></section>
</div>
    </main>
</div>
<!-- END  : inst/pkgdown/templates/content-extra.html -->

      </div>
<!--/div.row-->
      		<footer class="row footer mx-md-3"><hr>
<div class="col-md-6">
        <p>This lesson is subject to the <a href="CODE_OF_CONDUCT.html">Code of Conduct</a></p>
        <p>

        <a href="https://github.com/carpentries-incubator/machine-learning-responsible-python/edit/main/README.md" class="external-link">Edit on GitHub</a>

	
        | <a href="https://github.com/carpentries-incubator/machine-learning-responsible-python/blob/main/CONTRIBUTING.md" class="external-link">Contributing</a>
        | <a href="https://github.com/carpentries-incubator/machine-learning-responsible-python/" class="external-link">Source</a></p>
				<p><a href="https://github.com/carpentries-incubator/machine-learning-responsible-python/blob/main/CITATION.cff" class="external-link">Cite</a> | <a href="mailto:tpollard@mit.edu">Contact</a> | <a href="https://carpentries.org/about/" class="external-link">About</a></p>
			</div>
			<div class="col-md-6">

        <p>Materials licensed under <a href="LICENSE.html">CC-BY 4.0</a> by the authors</p>

        <p>Template licensed under <a href="https://creativecommons.org/licenses/by-sa/4.0/" class="external-link">CC-BY 4.0</a> by <a href="https://carpentries.org/" class="external-link">The Carpentries</a></p>
        <p>Built with <a href="https://github.com/carpentries/sandpaper/tree/0.16.10" class="external-link">sandpaper (0.16.10)</a>, <a href="https://github.com/carpentries/pegboard/tree/0.7.7" class="external-link">pegboard (0.7.7)</a>, and <a href="https://github.com/carpentries/varnish/tree/1.0.5" class="external-link">varnish (1.0.5)</a></p>
			</div>
		</footer>
</div> <!-- / div.container -->
	<div id="to-top">
		<a href="#top">
      <i class="search-icon" data-feather="arrow-up" role="img" aria-label="Back To Top"></i><br><!-- <span class="d-none d-sm-none d-md-none d-lg-none d-xl-block">Back</span> To Top --><span class="d-none d-sm-none d-md-none d-lg-none d-xl-block">Back</span> To Top
		</a>
	</div>
  <script type="application/ld+json">
    {
  "@context": "https://schema.org",
  "@type": "TrainingMaterial",
  "@id": "https://carpentries-incubator.github.io/machine-learning-responsible-python/instructor/aio.html",
  "inLanguage": "en",
  "dct:conformsTo": "https://bioschemas.org/profiles/TrainingMaterial/1.0-RELEASE",
  "description": "A Carpentries Lesson teaching foundational data and coding skills to researchers worldwide",
  "keywords": "software, data, lesson, The Carpentries",
  "name": "All in One View",
  "creativeWorkStatus": "active",
  "url": "https://carpentries-incubator.github.io/machine-learning-responsible-python/instructor/aio.html",
  "identifier": "https://carpentries-incubator.github.io/machine-learning-responsible-python/instructor/aio.html",
  "dateCreated": "2021-10-22",
  "dateModified": "2025-01-07",
  "datePublished": "2025-01-07"
}

  </script><script>
		feather.replace();
	</script>
</body>
</html><!-- END:   inst/pkgdown/templates/layout.html-->

